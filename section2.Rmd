---
title: "Section 2"
author: "PSTAT 115, Fall 2018"
date: "October 10, 2018"
output:
  pdf_document: default
  html_document:
    df_print: paged
urlcolor: blue
---
  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo=TRUE, 
                      cache=FALSE, 
                      fig.width=5, 
                      fig.height=5,
                      fig.align='center')
library(tidyverse)
library(ggplot2)
```

# Generative Models (continuation from class)
  
  If you ever want to just experiment with numbers, there are a bunch of handy datasets built into common R packages. To see them type:
  
```{r}
data()
```

Let's use one of these to talk about generating models + covariates.
 
ChickWeight is a dataset of weights collected over time for a number of different chicks on different diets. Let's load up the ChickWeight dataset into a tibble to make it easy to work with:

```{r}
df = ChickWeight %>% as.tibble
```

The ```%>%``` notation is a pipe in the tidyverse package. It is shorthand for:
  
```{r}
df = as.tibble(ChickWeight)
```

Using tibbles (instead of base R dataframes) and pipes (instead of function calls) can make it easier to do basic data transformations. You can do all of this in base R as well.

First let's print the ChickWeight tibble and see what's in it:

```{r}
df
```

Usually we'd look at the data before writing out a generating model. Just as an exercise though, let's do the reverse. We'll write out a generating model and then make some plots to see how reasonable our assumptions were.

* What is it that we are measuring?
    + Weight

* What other data did we collect to explain what we measured (covariates)?
    + Time
    + Chicken ID
    + Diet

The simplest thing we might assume is that errors in our measurements are normally distributed. This means:

$$\text{weight} \sim N(\mu, \sigma)$$

In this case, weight is fixed data, and we'll need to estimate $\mu$ and $\sigma$ (they are the estimands).

* What might be a limitation of the normal assumption here?
    + Our chickens grow over time. Lumping all the weights together at these different times won't produce a normal distribution.
    + There are multiple diets. Should every diet have the same mean?
    + Our outcomes appear to be discrete (looks like we'd never measure a weight of 75.33333 for instance)
    + Weights will be non-negative

How might we incorporate the chickens growing over time? We might assume that chickens grow linearly with time:

$$\text{weight}_i \sim N(\alpha t_i + \beta, \sigma)$$

In this case the new estimands are $\alpha$, $\beta$, and $\sigma$. $\text{weight}_i$ and $t_i$ are both data.

How might we expect the different diets to affect things? Maybe it doesn't affect the time zero weight of the chicken ($\beta$), but it does affect the slope ($\alpha$)? We can code in a diet dependence easily enough:

$$\text{weight}_{i, d} \sim N(\alpha_d t_i + \beta, \sigma)$$

The generating model also requires us to specify how the chickens are given a diet. We might assume this is uniformly sampled from the available diets, or something else. This is more important if we actually need to estimate the diet the chicken ate. In this case, the diet is given.

# Exploring our data

Since it is the weights we are concerned with, let's look at that first.

```{r}
df %>%
  ggplot(aes(weight)) +
  geom_histogram()
```

Perhaps unsurprisingly, this plot is mostly unintelligible. There's all sorts of things mixed together, so let's try to use some more plots to break it apart.

Let's have a look at $p(\text{weight} | \text{Time} = t)$.

```{r}
df %>%
  filter(Time == 16) %>%
  ggplot(aes(weight)) +
  geom_histogram()
```

If we assume this conditional distribution is normal, then we're saying the output (weight), is characterized by two parameters $\mu$ and $\sigma$ (that can be functions of the covariates). $\mu$ and $\sigma$ are our estimands here -- the things we'd try to estimate.

Let's try to get an idea of what $\mu(t)$ would look like by plotting weight vs. time:

```{r}
df %>%
  ggplot(aes(Time, weight)) +
  geom_point()
```

* How does this differ from what we proposed initially?
    + The noise is heteroskedastic (this means the amount of noise changes with another covariate -- in this case time)
    + The data is a bit non-linear

Let's try to get a handle on how diet affects any of this:

```{r}
df %>%
  ggplot(aes(Time, weight)) +
  geom_point(aes(color = Diet))
```

That's kindof hard to see. Maybe we can break this out into different plots:

```{r}
df %>%
  ggplot(aes(Time, weight)) +
  geom_point() +
  facet_wrap(~ Diet, nrow = 2, labeller = label_both)
```

* Does diet seem to have a strong affect on the growth of the chickens?
    + The effect isn't clear to me. Maybe someone else is more creative. At best maybe diet 4 produces more consistently sized chickens? But that seems like it could just be noise.
* What might be the next step in this analysis?
    + I'd feed food to more chickens. It's probably not that expensive to collect more data here.

* There were fifty chickens in this dataset. That is not all chickens. How do you think this dataset generalizes to other chickens? To other birds? To mammals?
    + I'm not sure if this dataset went all the way to adulthood.
    + I might expect that similar diet variations in other birds might not have a big effect (maybe this is my prior). If there was a big effect, then there might be something interesting that is different between chickens and these other birds worth investigating.
    + I would not expect the timescales or scale of the data to transfer.

# Bayesian Example

An example from BDA3 (the Gelman book in the syllabus) is a spelling correction problem. The problem setting is, assume that a user searched for "radom". The question is, what is the probability that they typed something else?

First assume that there are only three words to consider, "radom", "random", and "radon". Assume also that you've been given the likelihoods for typing "radom" given you actually wanted to type each of those three words and also the prior probability that each of those words was what was typed.

Likelihoods:

$$p(\text{typed radom} | \text{wanted to type random}) = 0.00193\\
p(\text{typed radom} | \text{wanted to type radon}) = 0.000143\\
p(\text{typed radom} | \text{wanted to type radom}) = 0.975$$

Priors:

$$p(\text{wanted to type random}) = 7.60 * 10^{-5}\\
p(\text{wanted to type radon}) = 6.05 * 10^{-6}\\
p(\text{wanted to type radom}) = 3.12 * 10^{-7}$$

Now we can use Bayes' rule to compute the posterior.

```{r}
likelihood = c(0.00193, 0.000143, 0.975)
prior = c(7.60e-5, 6.05e-6, 3.12e-7)

unnormalized_posterior = likelihood * prior
posterior = unnormalized_posterior / sum(unnormalized_posterior)
posterior
```

Posterior:

$$p(\text{wanted to type random} | \text{typed radom}) = 0.325\\
p(\text{wanted to type radon} | \text{typed radom}) = 0.002\\
p(\text{wanted to type radom} | \text{typed radom}) = 0.673$$

# Questions

- Was this what you expected?
    + The probability of no error seems high. Radom is a city in Poland though. Maybe it is a more popular topic of discussion than we might expect?

- How do you think the prior was estimated?
    + Empirical counts

- How do you think the likelihood was estimated?
    + Perhaps there was a study for this? Maybe a researcher sat hundreds of people down on keyboards and tried to understand the types of spelling mistakes that were more or less common